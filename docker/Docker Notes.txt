Docker :-

	https://github.com/redashu/24thmay2021_oracle/tree/day1
	https://github.com/redashu/24thmay2021_oracle/tree/day2
	https://github.com/redashu/24thmay2021_oracle/tree/day3

====================================================================================================================================

	1. Connecting remote docker engine :-
	If we want to connect remote docker engine from ec2 instance which IP is below instead of local docker engine default uses local docker engine.
	Create Context :- docker context create awsde --docker "host=tcp://52.21.252.231:2375"
	Using Context :- docker context use awsde
	Remove Context :- docker context rm awsde
	Listing Context :- docker context ls
	
====================================================================================================================================

	2. Install docker in linux :-
	Installing Docker :- yum  install docker  -y
	Configure docker engine to accept remote connection :-      
	[root@ip-172-31-71-168 ~]# cd  /etc/sysconfig/
[root@ip-172-31-71-168 sysconfig]# ls
	[root@ip-172-31-71-168 sysconfig]# vim docker
[root@ip-172-31-71-168 sysconfig]# cat  docker
# The max number of open files for the daemon itself, and all
# running containers.  The default value of 1048576 mirrors the value
# used by the systemd service unit.
DAEMON_MAXFILES=1048576
	# Additional startup options for the Docker daemon, for example:
# OPTIONS="--ip-forward=true --iptables=true"
# By default we limit the number of open files per container
OPTIONS="--default-ulimit nofile=1024:4096 -H tcp://0.0.0.0:2375"
	# How many seconds the sysvinit script waits for the pidfile to appear
# when starting the daemon.
DAEMON_PIDFILE_TIMEOUT=10
	Start Docker Engine :- 
	[root@ip-172-31-71-168 sysconfig]# systemctl start  docker 
[root@ip-172-31-71-168 sysconfig]# systemctl status  docker 
	[root@ip-172-31-71-168 sysconfig]# systemctl enable  docker 
	
	The above changes will done by docker desktop automatically it will install linux machine and perform the above operation to install docker and make it work.
	
====================================================================================================================================
	3. docker search java :- it will search from docker registry and list the images
====================================================================================================================================
	4. docker pull image name or docker pull image name : tag name (version)
====================================================================================================================================
	5. Container from images :- docker run --name rahul -d alpine : latest ping google.com
	docker  run  --name rahul -it -d   alpine  ping 127.0.0.1 or docker  run  --name rahul -itd   alpine  ping 127.0.0.1
	-d -> put container process in background (demon)
	--name -> name of the container
	ping google.com -> it is the parent process 
	run -> always create a new container
	-it -> where i is for interactive mode and t is for terminal to get shell access of container 
====================================================================================================================================
	6. List of running container :- docker ps
====================================================================================================================================
	7. List of all containers running or exited :- docker ps -a
====================================================================================================================================
	8. Stopping Container :- docker stop rahul (container name)
	Alternative :- docker kill rahul ajith priya ( multiple container name)
====================================================================================================================================
	9. Check output of any container parent process :- docker logs rahul (container name)
====================================================================================================================================
	10. Start a exited container :- docker start rahul (container name)
=====================================================================================================================================
	11. Login into the container in interactive mode to change the configuration inside the container :-
	docker exec -it rahul sh
	ifconfig -> to check ip
	uname & uname -r -> kernel 
	ps -e
=====================================================================================================================================
	12. history :- it will give all docker commands which we have run history data
=====================================================================================================================================
	13. To remove the container forever :- stop the container first and do ( docker rm rahul)
	Trick to remove containers and images (ALL)  :- 
	docker  rm  $(docker ps -aq) 
docker rmi $(docker images -q) -f
=====================================================================================================================================
	14. To check all the process running inside a container :-
	docker top rahul :- 
=====================================================================================================================================
	15. Creating docker image and running :- -f will be used if you want to use another file name for Dockerfile
	https://github.com/rahulkumarsahu/docker-kubernetes/blob/208cb25aacd59a2c03790b30744e617528f26741/docker/pythoncode/Dockerfile
	Building docker image from docker file :- docker build -t rahul:1.0.0 .
	-t -> will give the tag repo name with version like alpine is docker image name
	. -> it represent the current repository
	Creating docker container from docker image :-
	docker   run -itd --name or_rahul rahul:1.0.0
	It will take cmd as docker parent process 
	docker logs -f or_rahul -> to get the output in real time
	We cannot have multiple cmd commands in docker file because we can have only one parent process.
=====================================================================================================================================
	16. Docker will by default uses the docker hub repository to pull or push if we want to use OCR(Oracle Content Registry) then we should not do any changes 
	In docker client like we are using here my desktop as a client and ec2 instance as a docker engine remotely so we have configure there our ocr ip and port
	So that we can pull or push the images in our ocr.
	{
	  "registry-mirrors": [],
	  "insecure-registries": ["ip : port"],
	  "debug": false,
	  "experimental": false,
	  "features": {
	    "buildkit": true
	  },
	  "builder": {
	    "gc": {
	      "enabled": true,
	      "defaultKeepStorage": "20GB"
	    }
	  }
	}
	
=====================================================================================================================================
	17. https://slashdevops.blogspot.com/
=====================================================================================================================================
	18. Checking image build history :- docker history ded43eeaa386
=====================================================================================================================================
	19. Running application in httpd server :- 
	docker build -t rahul_httpd:1.0.0 .
	docker run -itd --name httpd_rahul -p 1294:80 rahul_httpd:1.0.0
	-p -> port forwarding 
	Access By 52.21.252.231:1294 (ec2 ip : port) give firewall access to ec2 so that we can access publicly
=====================================================================================================================================
	20. How to transfer the images from one docker engine to another docker engine because different team is using different docker engine
	
=====================================================================================================================================
	21. Pushing image to docker hub :- Same will be done for remote repository but how to configure remote repository in docker engine :- not needed
	Tagging docker image :- docker tag rahul_httpd:1.0.0 rahulkumar07/rahul_httpd:1.0.0 (docker hub user name/ image name : version)
	docker tag [OPTIONS] IMAGE[:TAG] [REGISTRYHOST/][USERNAME/]NAME[:TAG]
	docker push NAME[:TAG] -> docker push rahulkumar07/rahul_httpd:1.0.0
	docker tag 518a41981a6a myRegistry.com/image name
docker push myRegistry.com/image name
	Login Docker:- 
	docker login -u rahulkumar07
	docker logout
=====================================================================================================================================
	22. dumping internal information about docker images
	docker   inspect  ashuhttpd:18thmay2021v1
	docker   inspect  ashuhttpd:18thmay2021v1   --format='{{.Id}}'
	docker   inspect  ashuhttpd:18thmay2021v1   --format='{{.RepoTags}}'
	docker   inspect  ashuhttpd:18thmay2021v1   --format='{{.Cmd}}'
	docker   inspect  ashuhttpd:18thmay2021v1   --format='{{.ContainerConfig.Cmd}}'
=====================================================================================================================================
	23. Docker Networking (how ip assigned and container will have unique ip  and we can restrict memory and resources) :-
	 docker  run -itd  --name rahul1 --memory 100m   alpine ping google.com
	Listing :- docker network ls
	Info :- docker network inspect 11960b38a237
	docker stats rahul1
	docker  inspect   rahul1--format='{{.NetworkSettings.IPAddress}}' :- to check ip of container
	docker exec -it rahul1 sh :- login to container to check ip
	Ifconfig then ping 172.17.0.9
=====================================================================================================================================
	24. NAT () :- any container is allowed to reach outside internet when host is allowed to communicate and host ip is going outside not container ip
	docker exec -it rahul1 sh
	ping google.com
	/ # ping google.com
	PING google.com (142.250.81.206): 56 data bytes -> host ip is going out
	
	We can create our own bridge and on host you can change by default it will be docker0
	Make container available in publicly :- port forwarding
	Docker0 -> default bridge we should not use 
=====================================================================================================================================
	25. Creating docker network bridge 
	docker  network  create  rahul1 --subnet=192.168.250.0/24 :- give under 255 like 250
	
=====================================================================================================================================
	26. Creating container in my custom bridge
	docker run -itd --name rahul2 --network rahul1  alpine ping google.com -> it will take dynamically Ip
=====================================================================================================================================
	27. Creating container with static ip 
	docker run -itd --name rahul2 --network rahul1 --ip 192.168.250.20 alpine ping google.com -> it will take static ip (from point 25 )
	Container can connect with same bridge ip network not different bridge
	Connecting a bridge to a container :- docker network connect bridge1 bridge2
	                                                                  docker network disconnect bridge1 bridge2
=====================================================================================================================================
	28. Isolation between containers we will create different bridges for the container
	Why not to refer Docker0?
	What is host , bridge, none? All 3 types of default bridge and above networking is related to docker engine 
=====================================================================================================================================
	29. Remove bridge and no use bridge remove :-
	docker network rm bridge1
	Docker network prune
=====================================================================================================================================
	30. Partitioner.io ->  this is web ui for docker
docker  run -itd --name webui -p 8000:8000  -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer
=====================================================================================================================================
	31. Environment -> docker  run -it --rm  -e  x=500 -e z=hello  test:envv1  bash
=====================================================================================================================================
	32. Docker Storage :- If we remove the container that will remove the data also so that we have to persist our data so that we have to use the remote storage.
	
	Attaching external storage to host :- EC2 Instance where docker engine is installed and remotely from windows client we are using docker engine ec2
	
	[root@ip-172-31-71-168 ~]# 
[root@ip-172-31-71-168 ~]# lsblk                                                                                 --> It displays the list of block devices on your system.
NAME          MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
nvme0n1       259:0    0  100G  0 disk 
|-nvme0n1p1   259:1    0  100G  0 part /
`-nvme0n1p128 259:2    0    1M  0 part 
[root@ip-172-31-71-168 ~]# mkfs.xfs  -i size=512  /dev/nvme1n1
[root@ip-172-31-71-168 ~]# mkdir  /mnt/data
[root@ip-172-31-71-168 ~]# mount  /dev/nvme1n1  /mnt/data/
	
	Configure Docker Engine :-
	
	[root@ip-172-31-71-168 ~]# cd  /etc/sysconfig/
[root@ip-172-31-71-168 sysconfig]# ls
[root@ip-172-31-71-168 sysconfig]# cat  docker
# The max number of open files for the daemon itself, and all
# running containers.  The default value of 1048576 mirrors the value
# used by the systemd service unit.
DAEMON_MAXFILES=1048576
	# Additional startup options for the Docker daemon, for example:
# OPTIONS="--ip-forward=true --iptables=true"
# By default we limit the number of open files per container
OPTIONS="--default-ulimit nofile=1024:4096 -H tcp://0.0.0.0:2375 -g  /mnt/data"
	# How many seconds the sysvinit script waits for the pidfile to appear
# when starting the daemon.
DAEMON_PIDFILE_TIMEOUT=10
	Creating volume :-
	docker volume create rahul1 -> it will create one storage folder inside docker engine and we mounted new remote storage /mnt/oracle
	docker volume ls
	docker volume inspect rahul1 -> /mnt/oracle/volumes/rahul1/_data
	When we create volume in container it connect to docker engine storage if docker engine uses remote docker storage then it will get store in remote storage and data will be persist. And if local storage then data will get erased after container removal. 
	
	Creating Temp Container :-
	 docker  run -it  --rm   --name rahulstorage  -v   rahul1:/storage:rw   alpine  sh -> it will create the container and remove
	 docker  run -it   --name rahulstorage  -v   rahul1:/storage:rw   alpine  sh -> 
	 docker  run -it   --name rahulstorage  -v   rahul1:/storage:rw  -v   rahul2:/storage1:rw  alpine  sh
	 rahul1 -> Docker Volume name
	 storage -> this folder will be created inside container
	 rw -> permission
	
	Sharing data with different container :-
	docker  run -it --name rahulstorage1 -v  rahul1:/mnt/storage:ro    oraclelinux:8.3  bash
	
	Mounting a particular directory into container
	docker  run   -it --rm  -v  /etc:/myhostetc:ro   ubuntu   bash
	cat  /etc/os-release 
	ls
	cd  myhostetc/
	ls
	docker  run   -it --rm  -v  /etc:/myhostetc:ro  -v  ashuvol1:/okvol:rw   ubuntu   bash
	
=====================================================================================================================================
	33. Assignment :-
	Q1.   create  two containers and do the given things  
	Image must be alpine 
Name of container <your name>c1 & <your name>c2
Parent process you can choose accordingly 
Create two files in container1 named aa.txt & bb.txt 
Now copy aa.txt into second container
Under you custom bridge complete above task
	Solution :- 
	❯ docker  network  create  ashubr1  --subnet=192.168.200.0/24
3cc1ec68531002f63d74f1f12f566e8ee4e04cacd7b41581adf5a08434345e2d
❯ docker run -itd --name ashuc11  --network ashubr1  alpine ping fb.com
8f2f036b49bb8c9dc7bf773f6cd173f724047d8303ae0b05ab14e0e3a7c59b10
❯ docker run -itd --name ashuc12  --network ashubr1  alpine ping fb.com
a4b70bc3668eacecdf560a2b27afe3d27b09e7daff762b0fd07eb3ec04c031b5
❯ docker  exec -it ashuc11 sh
/ # pwd
/
/ # ls
bin    dev    etc    home   lib    media  mnt    opt    proc   root   run    sbin   srv    sys    tmp    usr    var
/ # echo  hello  >aa.txt 
/ # ls
aa.txt  dev     home    media   opt     root    sbin    sys     usr
bin     etc     lib     mnt     proc    run     srv     tmp     var
/ # echo world  >bb.txt 
/ # ls
aa.txt  bin     etc     lib     mnt     proc    run     srv     tmp     var
bb.txt  dev     home    media   opt     root    sbin    sys     usr
/ # exit
❯ docker  cp   ashuc11:/aa.txt  .
❯ ls
Applications          Documents             Movies                Public                awscli-bundle         k8susers
Creative Cloud Files  Downloads             Music                 VirtualBox VMs        go                    macos-terminal-themes
Desktop               Library               Pictures              aa.txt                javawebapp            powerlevel10k
❯ cat  aa.txt
hello
❯ docker  cp aa.txt  ashuc12:/
❯ docker  exec -it ashuc12 sh
/ # ls
aa.txt  dev     home    media   opt     root    sbin    sys     usr
bin     etc     lib     mnt     proc    run     srv     tmp     var
/ # cat aa.txt 
hello
/ # 
	
=====================================================================================================================================
	34. https://github.com/redashu/docker
	https://code.visualstudio.com/docs/containers/ssh
	https://docs.docker.com/engine/security/protect-access/
	
	
=====================================================================================================================================

	35. Docker compose :-
We cannont have multiple cmd and entrypoint in docker file.



Kubernetes :-
             https://github.com/redashu/k8s
             https://github.com/redashu/24thmay2021_oracle/tree/day3
             https://github.com/redashu/24thmay2021_oracle/tree/day4
             https://github.com/redashu/24thmay2021_oracle/tree/day5
             https://github.com/redashu/kubernetes
             https://github.com/redashu/day4kubernetesdeploy1
             https://github.com/redashu/k8s
             https://github.com/redashu/oracle17thmay2021/tree/day5

====================================================================================================================================================
	1. Master :- is a machine main system(handle 5000 nodes) that can listen instruction from client and manages minions and minions(nodes) are those machine in which we will deploy our container application.
====================================================================================================================================================
	2. kube-apiserver :- it is a part of master. As a developer or administration I can access only kube-apiserver it is like a rest end point. It can deal with authentication of user and authorization and ssl Certificate.
====================================================================================================================================================
	3. Etcd :- Consistent and highly-available key value store used as Kubernetes' backing store for all cluster data. kubectl get nodes -> it is getting from etcd. It is a brain of kubernetes
	Is your cluster healthy?
	
====================================================================================================================================================
	4. kube-scheduler :- The job is to find out the best minion or nodes to deploy your container. Kube-apiserver transfer this job to scheduler once pod is created. 

====================================================================================================================================================
	kubectl version --kubeconfig=admin.conf -> --kubeconfig is using the ec2 as master node.
	kubectl get nodes --kubeconfig=admin.conf -o json -> in which format we want output
	kubectl get nodes --kubeconfig=admin.conf -o yaml
	
	How to fix this --kubeconfig permanently instead of giving again and again? 
	Copy admin.conf into .kube folder and rename to config
	kubectl get nodes -> it will give same output
	SSL token on master node :- ec2 instance :- cd /etc/kubernetes/ then admin.conf -> this is kube server certificate
	Check certificate in project server :- if we want to access locally then we should have the config file in .kube file just install kubectl
	
====================================================================================================================================================
	
	5. Kube-controller-manager :- Reschedule , Scaling, Restarting 
	a. Replication Controller
	b. Node Controller :- it is used to scale minions or nodes and manage them  Responsible for noticing and responding when nodes go down.
	c. Job Controller :- Watches for Job objects that represent one-off tasks, then creates Pods to run those tasks to completion.
	
====================================================================================================================================================
	6. Kubelet :- Each compute node contains a kubelet, a tiny application that communicates with the control plane. The kubelet makes sure containers are running in a pod. When the control plane needs something to happen in a node, the kubelet executes the action.
	It is a agent which watches the nodes if anything failed it will inform master
	
====================================================================================================================================================
	7. Container Network Interface :- CNI -> it will not use Docker0 in k8s CNI will create its own bridge. it will have its own IP, DHCP, DNS, Subnet, NAT rules, calico.
	We will use Calico as CNI there are flannel, canal and others…
	Kube-proxy :- to maintain the communication b/w container across minion node.
	The kube-proxy handles network communications inside or outside of your cluster—relying either on your operating system’s packet filtering layer, or forwarding the traffic itself.

====================================================================================================================================================
Personal use :- minikube kubernetes cluster
Client has data center -> Kubeadm
Cloud as a service -> EKS, AKS

====================================================================================================================================================
	
Docker runtime has deprecated because docker comes with lot of things like swarm compose networking but for k8s it is not required it requires only containerization.
And by using containerd( it follows OCI rules) we can deploy our docker  container 
Open Container Initiative :- so any container tool we are using containerd, cri-o or docker they follow the open container initiative rules. So docker images will become container
By using any of the container tools because of rules.
Docker uses containerd for a creating image
https://opencontainers.org/#:~:text=The%20Open%20Container%20Initiative%20is,around%20container%20formats%20and%20runtimes.&text=The%20Runtime%20Specification%20outlines%20how,that%20is%20unpacked%20on%20disk.

Master Node managed by cloud services only as a developer we have to check nodes and kube-proxy
====================================================================================================================================================

	8. Creating pod using yaml file:-
	Dry run :- it will check the syntax. kubectl apply -f rahul.yaml --dry-run=client
	Create pod :- kubectl apply -f rahul.yaml
	To check node :- kubectl get po rahulpod-123 -o wide
====================================================================================================================================================
	9. Accessing container inside pod :- kubectl   exec  -it   rahulpod-123  -- bash
====================================================================================================================================================
	10. Logs :- kubectl logs rahulpod-123
====================================================================================================================================================
	11. Delete Pod :- kubectl delete pod rahulpod-123
====================================================================================================================================================
	12. Accessing the pod :- kubectl port-forward rahulpod-123 1294:80
====================================================================================================================================================
	13. Pod details :- kubectl describe po rahulpod-123
====================================================================================================================================================
	14. Best Practice :- 
	Creating namespace :- we can secure namespace
	kubectl get ns or namespace -> list of namespace
	kubectl delete ns rahul -> delete ns
	kubectl create ns rahul -> creating namespaces
	Default Namespaces are 4 :- default(), kube-public, kube-system, kube-node-lease
	All master and minion components are running in kube-system kubectl get po -n kube-system (we are able to see because we have admin.conf file)
	Set namespace in context :- kubectl config set-context --current --namespace=rahulns
	
====================================================================================================================================================
	15. Auto generate yaml file :- 
	kubectl  run   rahul1 --image=dockerashu/httpd:25thmay2021v1 --port 80  --dry-run=client 
kubectl  run   rahul1 --image=dockerashu/httpd:25thmay2021v1 --port 80  --dry-run=client -o yaml
kubectl  run   rahul1 --image=dockerashu/httpd:25thmay2021v1 --port 80  --dry-run=client -o json 
         kubectl  run   rahul1   --image=dockerashu/httpd:25thmay2021v1  --port=80  --dry-run=client  -o yaml  >rahulpod.yml
 
====================================================================================================================================================
	16. Accessing the po :- kubernetes client accessing the pods from client machine then how to access the pods
	kubectl port-forward rahul1 1234:80
	
====================================================================================================================================================
	17. Services :- 
	Pod has dynamic ip and we can have multiple pod for same application and every pod will be having different ip so we cannot share 
	different ip to user so we will create one service which has inbuilt functionality of load balancing and service will be having only one ip and all network related ingoing and 
	Outgoing will take care by service and we can expose our application to user or client by using service.
	
	Create service -> it has its own name it has its own ip and address and it uses label and tag where to forward request so that application 1 which has 2 replica should have same
	Label so that k8s service can transfer the request to correct application.  And similar for application 2 also.
	Cluster Ip :- for internal pod to pod communication
	Node Port, Load Balancer :- to access app from end user
	Node port :- it will create service in every worker node in which every node will be having unique ip and 
	
	If I create service s1 it will get created in every worker node 30000-32767
	
	Checking labels :- kubectl get po --show-labels (we can give any key value pair in yaml file as label)
	Node Port :- creating service (end user will have load balancer ip -> load balancer has all ip of worker nodes -> ip of worker nodes which is static ip of minions
	 -> svc of worker nodes -> application)
	end user hits rahul.com -> DNS server will have ip of load balancer -> load balancer -> ip of worker nodes -> svc of worker nodes -> application
           kubectl create service nodeport rahulsvc1 --tcp 1294:80 --dry-run=client -o yaml >rahulsvc1.yaml 
           kubectl apply -f .\rahulsvc1.yaml
           type:- nodeport
            name :- rahulsvc1
         
====================================================================================================================================================
	18. kubectl explain po 
====================================================================================================================================================
	19.  kubectl delete all --all -> to delete all in your namespace
====================================================================================================================================================
	20. Minikube :-
	Set docker context as default
	minikube start --driver=default
	minikube delete
	minikube dashboard
	To use again different one :-
	kubectl config get-contexts
           kubectl config use-contexts kubernetes-admin@kubernetes
	kubectl config use-context kubernetes-admin@kubernetes
	kubectl config use-context minikube
	To add worker node :- minikube add node
	minikube node delete name
	minikube ip
	minikube ssh
	
	kubectl get node
	
====================================================================================================================================================
kubeadm :-
====================================================================================================================================================
Every namespace has service account (kubectl get sa) and every service account has password which is stored in secret 
Secret is responsible is used for storing ssl or token or certificate. Secret is a client of etcd and secret will be created in ns.
When we create ns it will create automatically sa and secret
Namespace:-
====================================================================================================================================================
https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/
kubectl   describe   secret     kubernetes-dashboard-token-4nv4q     -n kubernetes-dashboard -> to get secret.
====================================================================================================================================================
Replication Controller :- Kubectl get rc
====================================================================================================================================================
Scale pods :- kubectl scale rc rahul-rc1 --replicas=5
====================================================================================================================================================
to automatch label of pod -- create service using expose
kubectl   expose   rc  rahul-rc   --type NodePort --port 1234 --target-port 80 --name rahulsvc2

====================================================================================================================================================
appending in the same file where rc was there
kubectl   expose   rc  ashurc-1   --type NodePort --port 1234 --target-port 80 --name ashusvc2  --dry-run=client -o yaml  

====================================================================================================================================================
Istio & Service Mesh :- https://www.youtube.com/watch?v=voAyroDb6xk&list=PLy7NrYWoggjyvPa2FNiLoxqH73rndE4La&index=2
Prometheus :- https://www.youtube.com/watch?v=h4Sl21AKiDg&list=PLy7NrYWoggjxCF3av5JKwyG7FFF9eLeL4
Kubernetes :- https://www.youtube.com/watch?v=VnvRFRk_51k&list=PLy7NrYWoggjziYQIDorlXjTvvwweTYoNC&index=1
====================================================================================================================================================
	Process of deployment :-
	1. First create a docker file with the requirement.
	2. build image from docker file -> docker  build  -t   dockerrahul/rahulnginx:v1 -f nginx.dockerfile   .
	3. Tag the docker image -> docker tag dockerrahul:1.0.0 oracleindia.azurecr.io/nginx:28thmay2021v1
	4. Push the image :- docker push oracleindia.azurecr.io/nginx:28thmay2021v1 
	5. kubectl describe for any issue in pod. kubectl replace -f ng.yaml --force -> to delete existing pod and create new one
	6. Create secret to connect with remote registry and define in yaml:-  kubectl  create  secret    docker-registry   rahulsec --docker-server=oracleindia.azurecr.io  --docker-username=oracleindia      --docker-password=pbJxt=N0nVD1FIqpDc1SP12UxjIpbAGd  -n  rahulns
	7. kubectl apply -f nginixpod.yaml
	8. kubectl expose pod rahulpod111 --type NodePort --port 1294 --target-port 80 --name rahulsvc1
====================================================================================================================================================

	Creating deployment:-
	kubectl  create  deployment   rahuldep111  --image=oracleindia.azurecr.io/nginx:28thmay2021v1  --dry-run=client -o yaml
	kubectl apply -f deployment.yaml
	kubectl scale deploy rahuldep111 --replicas=5
	
	kubectl  set  image  deployment  rahulweb javawebapp=dockerashu/javawebapp:28thmay2021_v2
	kubectl rollout history deployment rahulweb
	kubectl rollout undo deployment rahulweb
====================================================================================================================================================
Role Binding :-
	1. Creating namespace :- kubectl create namespace rahul-friend
	2. Creating SA :- kubectl create sa rahul -n rahul-friend
	3. Create friend.conf file and copy the data from .kube/config folder
	kubectl get sa -n rahul-friend
	kubectl get secret -n rahul-friend
	kubectl describe rahul-token-lwsls
	kubectl describe secret rahul-token-lwsls
	kubectl describe secret rahul-token-lwsls -n rahul-friend
	4. Create role file.
	5. Create role binding file :- it will bind role to config file.
	Kubectl get po --kubeconfig=friend.conf
	  kubectl apply -f role.yaml
	  kubectl apply -f .\role_binding.yaml
	  kubectl get po -n rahul-friend
	
	kubectl get ns --kubeconfig friend.conf -> it should not work

